#!/usr/bin/env python
"""
High-Nine æ•°æ®é›†é¡ºåºæµ‹è¯• - é€ä¸ªè°±å›¾å¤„ç†

ç‰¹ç‚¹:
1. æŒ‰è°±å›¾é¡ºåºé€ä¸ªå¤„ç†
2. De Novoé¢„æµ‹åç«‹å³é‡æ’åº
3. å®æ—¶æ˜¾ç¤ºè¿›åº¦å’Œç»“æœ
4. æ”¯æŒæ–­ç‚¹ç»­ä¼ 
5. æ¯ä¸ªè°±å›¾å¤„ç†å®Œç«‹å³ä¿å­˜ç»“æœ
"""

import pandas as pd
import subprocess
import time
import pickle
import json
from pathlib import Path
import re
from pyteomics import mgf
import sys
import torch
import numpy as np
from datetime import datetime
import logging
import einops
import collections

from casanovo.denovo.model import Spec2Pep
from casanovo.denovo.dataloaders import DeNovoDataModule
from casanovo.config import Config

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from efficient_reranker import EfficientReranker
from build_efficient_index import EfficientIndexBuilder

class SequentialProcessor:
    """é€ä¸ªè°±å›¾å¤„ç†å™¨"""
    
    def __init__(self, test_mgf, reference_mgf, index_file, output_dir, 
                 model_path="casanovo_v5_0_0_v5_0_0.ckpt", config_path="beam50.yaml"):
        self.test_mgf = test_mgf
        self.reference_mgf = reference_mgf
        self.index_file = index_file
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–é‡æ’åºå™¨
        print("Initializing reranker...")
        self.reranker = EfficientReranker(model_path=model_path, config_path=config_path)
        self.reranker.load_precomputed_index(index_file)
        
        # çŠ¶æ€æ–‡ä»¶
        self.state_file = self.output_dir / "processing_state.json"
        self.results_file = self.output_dir / "sequential_results.csv"
        self.temp_mgf_dir = self.output_dir / "temp_spectra"
        self.temp_mgf_dir.mkdir(exist_ok=True)
        
        # åŠ è½½æˆ–åˆå§‹åŒ–çŠ¶æ€
        self.state = self.load_state()
        
        # å¤ç”¨å·²åŠ è½½çš„Casanovoæ¨¡å‹ï¼ˆæ¥è‡ªé‡æ’åºå™¨ï¼‰ç”¨äºè§£ç 
        try:
            self.casa_model: Spec2Pep = self.reranker.model  # type: ignore
        except Exception:
            self.casa_model = None

    def is_unmodified(self, seq: str) -> bool:
        """åˆ¤æ–­è‚½æ®µæ˜¯å¦ä¸å¸¦ä¿®é¥°ï¼ˆä¸åŒ…å«æ‹¬å·/æ–¹æ‹¬å·/åŠ å·/æ•°å­—ï¼‰"""
        if seq is None:
            return False
        return re.search(r"[\[\]\(\)\+\d]", seq) is None

    def _extract_true_seq_from_params(self, params: dict) -> str:
        seq = params.get('seq', '')
        if not seq and 'title' in params:
            match = re.search(r'[Ss]eq[=:]([A-Z\[\]0-9\-\+\.]+)', params['title'])
            if match:
                seq = match.group(1)
        return seq
        
    def load_state(self):
        """åŠ è½½å¤„ç†çŠ¶æ€ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ """
        if self.state_file.exists():
            try:
                with open(self.state_file, 'r') as f:
                    state = json.load(f)
                print(f"Loaded existing state: processed {state['processed_count']}/{state['total_eligible']} spectra")
                return state
            except Exception as e:
                print(f"Failed to load state file, starting fresh: {e}")
        
        # åˆå§‹åŒ–æ–°çŠ¶æ€ï¼šé¢„æ‰«æå¯å¤„ç†ï¼ˆæ— ä¿®é¥°ï¼‰çš„è°±å›¾ç´¢å¼•
        eligible_indices = []
        total_spectra = 0
        with mgf.MGF(self.test_mgf) as reader:
            for idx, spec in enumerate(reader):
                total_spectra += 1
                true_seq = self._extract_true_seq_from_params(spec.get('params', {}))
                if self.is_unmodified(true_seq):
                    eligible_indices.append(idx)

        state = {
            'total_spectra': total_spectra,
            'eligible_indices': eligible_indices,
            'total_eligible': len(eligible_indices),
            'processed_count': 0,              # å¤„ç†åˆ°eligibleä¸­çš„ç¬¬å‡ ä¸ª
            'processed_indices': [],           # å®é™…å·²å¤„ç†çš„åŸå§‹è°±å›¾ç´¢å¼•
            'start_time': datetime.now().isoformat(),
            'last_update': datetime.now().isoformat(),
            'total_denovo_time': 0.0,
            'total_rerank_time': 0.0
        }
        
        # ä¿å­˜åˆå§‹çŠ¶æ€
        self.save_state(state)
        return state
    
    def save_state(self, state=None):
        """ä¿å­˜å¤„ç†çŠ¶æ€"""
        if state is None:
            state = self.state
        state['last_update'] = datetime.now().isoformat()
        with open(self.state_file, 'w') as f:
            json.dump(state, f, indent=2)
    
    def extract_single_spectrum(self, spec_idx, output_file):
        """æå–å•ä¸ªè°±å›¾åˆ°ä¸´æ—¶MGFæ–‡ä»¶"""
        try:
            with mgf.MGF(self.test_mgf) as reader:
                spectra_list = list(reader)
                if spec_idx >= len(spectra_list):
                    return None
                
                spectrum = spectra_list[spec_idx]
                
                # æå–ground truth
                true_seq = spectrum['params'].get('seq', '')
                if not true_seq and 'title' in spectrum['params']:
                    match = re.search(r'[Ss]eq[=:]([A-Z\[\]0-9\-\+\.]+)', spectrum['params']['title'])
                    if match:
                        true_seq = match.group(1)
                # ä»…å¤„ç†ä¸å¸¦ä¿®é¥°çš„æ ·æœ¬
                if not self.is_unmodified(true_seq):
                    return None

                # ä¿å­˜å•ä¸ªè°±å›¾
                with open(output_file, 'w') as writer:
                    mgf.write([spectrum], writer)
                
                return {
                    'spectrum_index': spec_idx,
                    'true_sequence': true_seq,
                    'precursor_mz': spectrum['params'].get('pepmass', [0])[0] if isinstance(spectrum['params'].get('pepmass'), (list, tuple)) else spectrum['params'].get('pepmass', 0),
                    'charge': spectrum['params'].get('charge', [2])[0] if isinstance(spectrum['params'].get('charge'), (list, tuple)) else spectrum['params'].get('charge', 2)
                }
        except Exception as e:
            print(f"Error extracting spectrum {spec_idx}: {e}")
            return None
    
    def _prepare_config_with_beams(self, base_yaml: str, beams: int) -> Path:
        """åŸºäºbeam50.yamlç”ŸæˆæŒ‡å®šn_beamsçš„ä¸´æ—¶é…ç½®ï¼Œtop_matchå›ºå®š50ï¼Œbatch_size=1"""
        temp_config = self.temp_mgf_dir / f"beam_{beams}_single.yaml"
        try:
            try:
                with open(base_yaml, "r", encoding="utf-8") as cf:
                    raw = cf.read()
            except Exception:
                raw = ""
            # è®¾ç½®predict_batch_size
            if raw:
                raw = re.sub(r'(?m)^\s*predict_batch_size\s*:\s*\d+\s*$', 'predict_batch_size: 1', raw)
                if 'predict_batch_size' not in raw:
                    raw += "\npredict_batch_size: 1\n"
                # è®¾ç½®n_beams å’Œ top_match
                raw = re.sub(r'(?m)^\s*n_beams\s*:\s*\d+\s*$', f'n_beams: {beams}', raw)
                if 'n_beams' not in raw:
                    raw += f"\nn_beams: {beams}\n"
                raw = re.sub(r'(?m)^\s*top_match\s*:\s*\d+\s*$', 'top_match: 50', raw)
                if 'top_match' not in raw:
                    raw += "\ntop_match: 50\n"
            else:
                raw = f"n_beams: {beams}\ntop_match: 50\npredict_batch_size: 1\n"
            with open(temp_config, "w", encoding="utf-8") as sf:
                sf.write(raw)
        except Exception as e:
            print(f"Warning: failed to prepare config for beams={beams}: {e}")
            temp_config = Path(base_yaml)
        return temp_config

    def _progressive_decode_single(self, spectrum_file: Path, branch_k: int = 20, beam_k: int = 50, top_match: int = 50):
        """ä½¿ç”¨Casanovo Python APIè¿›è¡Œé€æ­¥beamè§£ç ï¼šæ¯æ­¥æ¯çˆ¶beamæ‰©å±•branch_kï¼Œåˆå¹¶åå…¨å±€ä¿ç•™beam_kï¼Œè¾“å‡ºtop_matchå€™é€‰ã€‚"""
        if self.casa_model is None:
            # å›é€€ï¼šä»é‡æ’åºå™¨çš„æ¨¡å‹è·¯å¾„å†è½½å…¥
            logging.info("Loading Spec2Pep model for progressive decode from reranker path...")
            self.casa_model = Spec2Pep.load_from_checkpoint("casanovo_v5_0_0_v5_0_0.ckpt", map_location=self.reranker.device)  # type: ignore
            self.casa_model.eval()
            self.casa_model.to(self.reranker.device)

        # ç”¨æ•°æ®æ¨¡å—åšä¸CLIä¸€è‡´çš„é¢„å¤„ç†
        cfg = Config()
        lance_dir = self.temp_mgf_dir / f"lance_{int(time.time())}"
        dm = DeNovoDataModule(
            lance_dir=str(lance_dir),
            test_paths=[str(spectrum_file)],
            eval_batch_size=1,
            min_peaks=cfg.min_peaks,
            max_peaks=cfg.max_peaks,
            min_mz=cfg.min_mz,
            max_mz=cfg.max_mz,
            min_intensity=cfg.min_intensity,
            remove_precursor_tol=cfg.remove_precursor_tol,
            max_charge=cfg.max_charge,
            n_workers=0
        )
        dm.setup(stage="test", annotated=False)
        loader = dm.predict_dataloader()

        # ä¸ºé¿å… depthcharge tokenizer åœ¨GPU/CPUæ··ç”¨å¯¼è‡´çš„è®¾å¤‡ä¸ä¸€è‡´ï¼Œå¼ºåˆ¶åœ¨CPUä¸Šè¿›è¡Œprogressiveè§£ç 
        original_device = self.reranker.device
        device = torch.device('cpu')
        model = self.casa_model
        model.to(device)
        model.top_match = top_match
        model.n_beams = beam_k  # ç”¨ä½œç¼“å­˜å¤§å°

        candidates = []
        with torch.no_grad():
            for batch in loader:
                mzs = batch["mz_array"].to(device)
                intensities = batch["intensity_array"].to(device)
                precursor_mz = batch["precursor_mz"].to(device)
                precursor_charge = batch["precursor_charge"].to(device)
                precursors = torch.stack([mzs.new_tensor(0.0).expand_as(precursor_mz), precursor_charge.float(), precursor_mz], dim=1)

                # åŸºäºbeam_search_decodeæ”¹å†™ï¼Œå±€éƒ¨branch_kï¼Œå…¨çƒbeam_k
                memories, mem_masks = model.encoder(mzs, intensities)
                B = mzs.shape[0]
                L = model.max_peptide_len + 1
                V = model.vocab_size
                S = beam_k

                scores = torch.full((B, L, V, S), float('nan'), device=device)
                tokens = torch.zeros(B, L, S, dtype=torch.int64, device=device)

                pred_cache = collections.OrderedDict((i, []) for i in range(B))

                pred = model.decoder(tokens=torch.zeros(B, 0, dtype=torch.int64, device=device), memory=memories, memory_key_padding_mask=mem_masks, precursors=precursors)

                # ç¬¬ä¸€æ­¥ï¼šæ¯beamå–branch_kï¼Œä½†èµ·å§‹åªæœ‰ä¸€ä¸ªçˆ¶beam -> ç›´æ¥å–branch_k
                top_indices = torch.topk(pred[:, 0, :], branch_k, dim=1)[1]
                # å¡«å……åˆ°Såˆ—ï¼Œå‰branch_kä¸ºæœ‰æ•ˆï¼Œå…¶ä½™å¤åˆ¶æœ€åä¸€ä¸ªï¼Œé¿å…NaN
                tokens[:, 0, :branch_k] = top_indices
                tokens[:, 0, branch_k:] = top_indices[:, -1:].expand(B, S - branch_k)
                scores[:, :1, :, :] = einops.repeat(pred, "B L V -> B L V S", S=S)

                model._batch_size = B
                model._beam_size = S
                model._cumulative_masses = torch.zeros(B * S, device=device)

                # å±•å¼€åˆ°(B*S)
                precursors_rep = einops.repeat(precursors, "B L -> (B S) L", S=S)
                mem_masks_rep = einops.repeat(mem_masks, "B L -> (B S) L", S=S)
                memories_rep = einops.repeat(memories, "B L V -> (B S) L V", S=S)
                tokens_rep = einops.rearrange(tokens, "B L S -> (B S) L")
                scores_rep = einops.rearrange(scores, "B L V S -> (B S) L V")

                # ä¸»å¾ªç¯
                for step in range(0, model.max_peptide_len):
                    finished_beams, beam_fits_precursor, discarded_beams = model._finish_beams(tokens_rep, precursors_rep, step)

                    beams_to_cache = finished_beams & ~discarded_beams
                    if torch.any(beams_to_cache):
                        model._cache_finished_beams(tokens_rep, scores_rep, step, beams_to_cache, beam_fits_precursor, pred_cache)

                    finished_beams |= discarded_beams
                    if torch.all(finished_beams):
                        break

                    # ä»…å¯¹æ´»è·ƒbeamè®¡ç®—ä¸‹ä¸€æ­¥
                    active = ~finished_beams
                    if torch.any(active):
                        active_tokens = tokens_rep[active, : step + 1]
                        active_precursors = precursors_rep[active]
                        active_memories = memories_rep[active]
                        active_mem_masks = mem_masks_rep[active]
                        active_scores = model.decoder(tokens=active_tokens, precursors=active_precursors, memory=active_memories, memory_key_padding_mask=active_mem_masks)
                        scores_rep[active, : step + 2, :] = active_scores

                    # è‡ªå®šä¹‰é€‰æ‹©ï¼šæ¯ä¸ªçˆ¶beamå–branch_kï¼Œå†å…¨å±€ä¿ç•™S
                    # è¿˜åŸåˆ°(B,S)åˆ†ç»„
                    tokens_bs = einops.rearrange(tokens_rep, "(B S) L -> B L S", S=S)
                    scores_bsv = einops.rearrange(scores_rep, "(B S) L V -> B L V S", S=S)

                    # åœ¨å½“å‰æ­¥ä¸ºæ¯ä¸ªçˆ¶beamé€‰æ‹©branch_kä¸ªtoken
                    logits = scores_bsv[:, step, :, :]  # B, V, S
                    logits = einops.rearrange(logits, "B V S -> B S V")
                    topk_vals, topk_idx = torch.topk(logits, k=branch_k, dim=2)

                    # ç»„åˆæ‰€æœ‰æ‰©å±•ï¼Œå½¢æˆ(B, S*branch_k)å€™é€‰ï¼Œç„¶åæŒ‰å‡å€¼åˆ†æ•°æ’åºå–S
                    # è®¡ç®—åˆ°å½“å‰çš„å‡å€¼åˆ†æ•°ï¼ˆç”¨nanmeané¿å…NaNï¼‰
                    prev_tokens = tokens_bs[:, : step + 1, :]
                    prev_scores = torch.gather(scores_bsv[:, : step + 1, :, :], dim=2, index=einops.repeat(prev_tokens, "B L S -> B L 1 S").expand(-1, -1, 1, -1))
                    prev_scores = prev_scores[:, :, 0, :]  # B, L, S
                    prev_mean = torch.nanmean(prev_scores, dim=1)  # B, S

                    # æ–°tokençš„å¾—åˆ†å–å¯¹åº”æ¦‚ç‡
                    new_vals = topk_vals  # B, S, K
                    # åˆæˆå€™é€‰å¾—åˆ†ï¼šç®€å•å¹³å‡ï¼ˆç­‰ä»·äºé™„åŠ ä¸€æ­¥åæ–°çš„å‡å€¼ï¼‰
                    new_mean = (prev_mean.unsqueeze(-1) * (step + 1) + new_vals) / (step + 2)  # B, S, K

                    # é€‰å…¨å±€Top-S
                    new_mean_flat = einops.rearrange(new_mean, "B S K -> B (S K)")
                    best_vals, best_idx = torch.topk(new_mean_flat, k=S, dim=1)
                    # åæ¨å¯¹åº”çš„çˆ¶beamå’Œtoken
                    parent_idx = best_idx // branch_k  # B, S
                    token_sel = best_idx % branch_k    # B, S
                    v_idx = torch.gather(topk_idx, 2, token_sel.unsqueeze(-1)).squeeze(-1)  # B, S

                    # é‡ç»„tokens/scoresåˆ°ä¸‹ä¸€è½®
                    gather_parent = parent_idx
                    b_idx = torch.arange(B, device=device).unsqueeze(-1).expand_as(gather_parent)
                    tokens_bs[:, : step + 1, :] = tokens_bs[b_idx, : step + 1, gather_parent]
                    tokens_bs[:, step + 1, :] = v_idx

                    scores_bsv[:, : step + 2, :, :] = scores_bsv[b_idx, : step + 2, :, gather_parent]
                    # å›å†™å±•å¹³è¡¨ç¤º
                    tokens_rep = einops.rearrange(tokens_bs, "B L S -> (B S) L")
                    scores_rep = einops.rearrange(scores_bsv, "B L V S -> (B S) L V")

                # æ”¶é›†ç»“æœï¼ˆä¸æ¨¡å‹ä¸€è‡´ï¼‰
                top_list = list(model._get_top_peptide(pred_cache))[0]
                for (pep_score, _aa_scores, seq) in top_list:
                    if self.is_unmodified(seq):
                        candidates.append({
                            'peptide': seq,
                            'score': float(pep_score)
                        })

        # å°†æ¨¡å‹ç§»å›åŸè®¾å¤‡ï¼ˆä¾›åç»­rerankç»§ç»­ä½¿ç”¨GPUï¼‰
        try:
            model.to(original_device)
        except Exception:
            pass

        # æ¸…ç†lanceç›®å½•
        try:
            import shutil
            shutil.rmtree(lance_dir, ignore_errors=True)
        except Exception:
            pass

        # æ’åºå¹¶è¿”å›Top-50
        candidates.sort(key=lambda x: x['score'], reverse=True)
        return candidates[:top_match]

    def run_denovo_single(self, spectrum_file, spec_idx):
        """å¯¹å•ä¸ªè°±å›¾è¿è¡ŒDe Novoé¢„æµ‹ï¼ˆè‡ªå®šä¹‰progressive beamï¼šç¬¬0æ­¥20ï¼Œç¬¬1æ­¥20*20->50ï¼Œåç»­50*20->50ï¼‰"""
        start_time = time.time()
        try:
            candidates = self._progressive_decode_single(Path(spectrum_file), branch_k=20, beam_k=50, top_match=50)
            return candidates, time.time() - start_time
        except Exception as e:
            print(f"Progressive decode failed for spectrum {spec_idx}: {e}")
            import traceback; traceback.print_exc()
            return None, time.time() - start_time
    
    def parse_mztab_single(self, mztab_file, spec_idx):
        """è§£æå•ä¸ªè°±å›¾çš„mzTabç»“æœ"""
        candidates = []
        try:
            with open(mztab_file, 'r', encoding="utf-8") as f:
                header = None
                for line in f:
                    if line.startswith('PSH'):
                        header = line.strip().split('\t')[1:]
                    elif line.startswith('PSM'):
                        values = line.strip().split('\t')[1:]
                        if header:
                            row = dict(zip(header, values))
                            peptide = row.get('sequence', '').strip()
                            score = float(row.get('search_engine_score[1]', 0))
                            # ä»…ä¿ç•™ä¸å¸¦ä¿®é¥°çš„å€™é€‰
                            if peptide and self.is_unmodified(peptide):
                                candidates.append({
                                    'peptide': peptide,
                                    'score': score
                                })
            
            # æŒ‰åˆ†æ•°æ’åºï¼ˆé™åºï¼‰
            candidates.sort(key=lambda x: x['score'], reverse=True)
            
            print(f"  â”œâ”€ De Novo candidates found: {len(candidates)}")
            if candidates:
                print(f"  â”œâ”€ Top 3 candidates:")
                for i, candidate in enumerate(candidates[:3], 1):
                    print(f"     {i}. {candidate['peptide']:20} (score: {candidate['score']:.3f})")
            
            # é™åˆ¶å€™é€‰æ•°é‡
            return candidates[:50]
            
        except Exception as e:
            print(f"Error parsing mztab for spectrum {spec_idx}: {e}")
            return []
    
    def rerank_single_spectrum(self, spec_idx, candidates, spectrum_info):
        """å¯¹å•ä¸ªè°±å›¾è¿›è¡Œé‡æ’åº"""
        if not candidates:
            return None
        
        start_time = time.time()
        try:
            # åˆ›å»ºä¸´æ—¶è°±å›¾æ–‡ä»¶ç”¨äºé‡æ’åº
            temp_spectrum_file = self.temp_mgf_dir / f"spectrum_{spec_idx}.mgf"
            spectrum_data = self.extract_single_spectrum(spec_idx, temp_spectrum_file)
            
            if spectrum_data is None:
                return None
            
            # å…³é”®ä¿®å¤ï¼šå¯¹äºå•ä¸ªè°±å›¾çš„ä¸´æ—¶æ–‡ä»¶ï¼Œç´¢å¼•åº”è¯¥æ˜¯0
            result = self.reranker.rerank_with_efficient_index(
                str(temp_spectrum_file),
                0,  # å•ä¸ªè°±å›¾æ–‡ä»¶ä¸­çš„ç´¢å¼•æ€»æ˜¯0
                candidates,
                use_prosit=True,
                top_k=3
            )
            
            rerank_time = time.time() - start_time
            
            # æ·»åŠ é¢å¤–ä¿¡æ¯
            result.update({
                'spectrum_index': spec_idx,
                'true_sequence': spectrum_info['true_sequence'],
                'precursor_mz': spectrum_info['precursor_mz'],
                'charge': spectrum_info['charge'],
                'denovo_time': spectrum_info.get('denovo_time', 0),
                'rerank_time': rerank_time,
                'total_time': spectrum_info.get('denovo_time', 0) + rerank_time
            })
            
            return result
            
        except Exception as e:
            print(f"Error reranking spectrum {spec_idx}: {e}")
            return None
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            temp_file = self.temp_mgf_dir / f"spectrum_{spec_idx}.mgf"
            if temp_file.exists():
                temp_file.unlink()
    
    def save_single_result(self, result):
        """ä¿å­˜å•ä¸ªè°±å›¾çš„ç»“æœ"""
        if result is None:
            return
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame([result])
        
        # å¦‚æœç»“æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶ï¼›å¦åˆ™è¿½åŠ 
        if not self.results_file.exists():
            df.to_csv(self.results_file, index=False)
        else:
            df.to_csv(self.results_file, mode='a', header=False, index=False)
    
    def print_progress(self, spec_idx, spectrum_info):
        """æ‰“å°è¯¦ç»†çš„è¿›åº¦ä¿¡æ¯"""
        processed = self.state['processed_count']
        total = self.state.get('total_eligible', self.state.get('total_spectra', 0))
        progress = (processed / total) * 100
        
        # è®¡ç®—æ—¶é—´ç»Ÿè®¡
        total_elapsed = time.time() - self._get_start_time()
        avg_time = total_elapsed / processed if processed > 0 else 0
        remaining = (total - processed) * avg_time
        
        # å½“å‰è°±å›¾ä¿¡æ¯
        denovo_time = spectrum_info.get('denovo_time', 0)
        rerank_time = spectrum_info.get('rerank_time', 0)
        total_time = denovo_time + rerank_time
        
        # è·å–å€™é€‰ä¿¡æ¯
        candidates = spectrum_info.get('candidates', [])
        result = spectrum_info.get('result', {})
        true_seq = spectrum_info.get('true_sequence', '')
        
        print(f"\n{'='*70}")
        print(f"[{processed+1}/{total}] {progress:.1f}% | Spectrum {spec_idx}")
        print(f"{'='*70}")
        print(f"â±ï¸  Timing: De Novo {denovo_time:.2f}s | Rerank {rerank_time:.2f}s | Total {total_time:.2f}s")
        print(f"ğŸ¯ True Sequence: {true_seq}")
        
        # æ˜¾ç¤ºCasanovo Top 5
        if candidates:
            print(f"\nğŸ”¬ Casanovo Top 5 Candidates:")
            for i, candidate in enumerate(candidates[:5], 1):
                peptide = candidate['peptide']
                score = candidate['score']
                is_correct = False
                if true_seq:
                    pred_seq = self.reranker.normalize_peptide(peptide)
                    true_seq_clean = self.reranker.normalize_peptide(true_seq)
                    is_correct = pred_seq == true_seq_clean and true_seq_clean != ''
                check = 'âœ“' if is_correct else ' '
                print(f"   {i}. {peptide:20} (score: {score:.3f}) {check}")
        
        # æ˜¾ç¤ºé‡æ’åºç»“æœ
        if result and result.get('peptide'):
            pred_source = result.get('source', 'Unknown')
            similarity_score = result.get('similarity', -1.0)
            denovo_score = result.get('denovo_score', -1.0)
            
            # æ¥æºå›¾æ ‡
            source_icon = {
                'Database': 'ğŸ—„ï¸',
                'Prosit': 'ğŸ§¬', 
                'DeNovoFallback': 'ğŸ”„',
                'DeNovo': 'ğŸ”¬',
                'NoResults': 'âŒ',
                'Error': 'âš ï¸'
            }.get(pred_source, 'â“')
            
            print(f"\nğŸ† Rerank Top 1:")
            print(f"   Peptide: {result['peptide']} {source_icon}({pred_source})")
            if similarity_score >= 0:
                print(f"   Similarity: {similarity_score:.4f}")
            if denovo_score >= 0:
                print(f"   De Novo Score: {denovo_score:.3f}")
            
            # åˆ¤æ–­é‡æ’åºç»“æœæ˜¯å¦æ­£ç¡®
            is_rerank_correct = False
            if true_seq and result['peptide']:
                pred_seq = self.reranker.normalize_peptide(result['peptide'])
                true_seq_clean = self.reranker.normalize_peptide(true_seq)
                is_rerank_correct = pred_seq == true_seq_clean and true_seq_clean != ''
            
            # å¯¹æ¯”Casanovo Top 1 vs Rerank Top 1
            if candidates:
                casanovo_top1 = candidates[0]
                casanovo_correct = False
                if true_seq and casanovo_top1['peptide']:
                    pred_seq = self.reranker.normalize_peptide(casanovo_top1['peptide'])
                    true_seq_clean = self.reranker.normalize_peptide(true_seq)
                    casanovo_correct = pred_seq == true_seq_clean and true_seq_clean != ''
                
                print(f"\nğŸ“Š Comparison:")
                print(f"   Casanovo Top 1: {casanovo_top1['peptide']:20} (rank: 1, score: {casanovo_top1['score']:.3f}) {'âœ“' if casanovo_correct else 'âœ—'}")
                
                # æ‰¾åˆ°é‡æ’åºç»“æœåœ¨åŸå§‹Casanovoåˆ—è¡¨ä¸­çš„ä½ç½®
                rerank_peptide = result['peptide']
                original_rank = None
                for i, candidate in enumerate(candidates):
                    if candidate['peptide'] == rerank_peptide:
                        original_rank = i + 1
                        break
                
                if original_rank is not None:
                    print(f"   Rerank Top 1:   {result['peptide']:20} (original rank: {original_rank}, similarity: {similarity_score:.4f}) {'âœ“' if is_rerank_correct else 'âœ—'}")
                else:
                    print(f"   Rerank Top 1:   {result['peptide']:20} (new candidate, similarity: {similarity_score:.4f}) {'âœ“' if is_rerank_correct else 'âœ—'}")
                
                # æ˜¾ç¤ºé‡æ’åºæ•ˆæœ
                if casanovo_top1['peptide'] == result['peptide']:
                    print(f"   ğŸ“Š Reranking: No change (kept original top 1)")
                else:
                    if original_rank:
                        if original_rank > 1:
                            print(f"   ğŸ”„ Reranking: Promoted from rank {original_rank} to rank 1")
                        else:
                            print(f"   ğŸ”„ Reranking: Changed prediction")
                    else:
                        print(f"   ğŸ”„ Reranking: Selected different candidate")
                    
                    if casanovo_correct and not is_rerank_correct:
                        print(f"   âš ï¸  Result: Reranking made it worse")
                    elif not casanovo_correct and is_rerank_correct:
                        print(f"   ğŸ‰ Result: Reranking fixed it! (improved accuracy)")
                    elif not casanovo_correct and not is_rerank_correct:
                        print(f"   ğŸ“ˆ Result: Both wrong, but different approach")
                    else:
                        print(f"   âœ… Result: Both correct")
                        
                # æ˜¾ç¤ºç›¸ä¼¼åº¦å¦‚ä½•å½±å“æ’å
                if similarity_score >= 0:
                    print(f"   ğŸ“ˆ Similarity Analysis:")
                    print(f"      Top similarity: {similarity_score:.4f}")
                    if original_rank and original_rank > 1:
                        print(f"      Original score: {casanovo_top1['score']:.3f}")
                        print(f"      Selected score: {candidates[original_rank-1]['score']:.3f}")
                        print(f"      âœ… Similarity overrode De Novo score")
                    elif original_rank == 1:
                        print(f"      âœ… De Novo top 1 confirmed by similarity")
                else:
                    print(f"   â“ Similarity: No similarity score available")
        else:
            print(f"\nâŒ Reranking failed - using Casanovo Top 1")
        
        print(f"\nâ³ ETA: {remaining:.1f}s | Avg: {avg_time:.2f}s/spectrum")
    
    def _get_start_time(self):
        """è·å–å¼€å§‹æ—¶é—´æˆ³"""
        try:
            from datetime import datetime
            return datetime.fromisoformat(self.state['start_time']).timestamp()
        except:
            return time.time()
    
    def process_all(self):
        """å¤„ç†æ‰€æœ‰è°±å›¾"""
        total_eligible = self.state.get('total_eligible', 0)
        print(f"Starting sequential processing of {total_eligible} unmodified spectra (out of {self.state['total_spectra']})...")
        print(f"Resume from eligible position {self.state['processed_count']}")
        print("="*70)

        correct_count = 0
        total_processed = 0

        eligible = self.state.get('eligible_indices', list(range(self.state.get('total_spectra', 0))))
        for pos in range(self.state['processed_count'], len(eligible)):
            spec_idx = eligible[pos]
            if spec_idx in self.state['processed_indices']:
                # å·²å¤„ç†åˆ™æ¨è¿›è®¡æ•°æŒ‡é’ˆ
                self.state['processed_count'] = pos + 1
                self.save_state()
                continue
            
            # æå–è°±å›¾ä¿¡æ¯
            temp_spectrum_file = self.temp_mgf_dir / f"temp_{spec_idx}.mgf"
            spectrum_info = self.extract_single_spectrum(spec_idx, temp_spectrum_file)
            
            if spectrum_info is None:
                print(f"Skipping spectrum {spec_idx} (extraction failed)")
                continue
            
            # De Novoé¢„æµ‹
            candidates, denovo_time = self.run_denovo_single(temp_spectrum_file, spec_idx)
            spectrum_info['denovo_time'] = denovo_time
            spectrum_info['candidates'] = candidates  # ä¿å­˜å€™é€‰ä¿¡æ¯
            
            if candidates is None:
                print(f"Skipping spectrum {spec_idx} (denovo failed)")
                temp_spectrum_file.unlink()
                continue
            
            # é‡æ’åº
            result = self.rerank_single_spectrum(spec_idx, candidates, spectrum_info)
            spectrum_info['result'] = result
            spectrum_info['rerank_time'] = result.get('rerank_time', 0) if result else 0
            
            # ä¿å­˜ç»“æœ
            if result:
                self.save_single_result(result)
                
                # ç»Ÿè®¡æ­£ç¡®ç‡
                pred_seq = self.reranker.normalize_peptide(result.get('peptide', ''))
                true_seq = self.reranker.normalize_peptide(spectrum_info['true_sequence'])
                if true_seq != '' and pred_seq == true_seq:
                    correct_count += 1
                total_processed += 1
            
            # æ›´æ–°çŠ¶æ€
            self.state['processed_count'] += 1
            self.state['processed_indices'].append(spec_idx)
            self.state['total_denovo_time'] += denovo_time
            self.state['total_rerank_time'] += spectrum_info.get('rerank_time', 0)
            self.save_state()
            
            # æ˜¾ç¤ºè¿›åº¦
            self.print_progress(spec_idx, spectrum_info)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_spectrum_file.exists():
                temp_spectrum_file.unlink()
        
        # æœ€ç»ˆç»Ÿè®¡
        print("\n" + "="*70)
        print("PROCESSING COMPLETE!")
        print("="*70)
        print(f"Total spectra processed: {total_processed}")
        print(f"Correct predictions: {correct_count}")
        print(f"Accuracy: {correct_count/total_processed*100:.2f}%" if total_processed > 0 else "Accuracy: N/A")
        print(f"Total De Novo time: {self.state['total_denovo_time']:.1f}s")
        print(f"Total rerank time: {self.state['total_rerank_time']:.1f}s")
        print(f"Average time per spectrum: {(self.state['total_denovo_time'] + self.state['total_rerank_time'])/total_processed:.2f}s" if total_processed > 0 else "N/A")
        print(f"Results saved to: {self.results_file}")
        print("="*70)

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®è·¯å¾„
    test_mgf = "test_data/high_nine/high_nine_validation_1000.mgf"
    reference_mgf = "test_data/high_nine/high_nine_database.mgf"
    index_file = f"{reference_mgf}.efficient_index.pkl"
    output_dir = Path("high_nine_results_sequential")
    
    # æ£€æŸ¥ç´¢å¼•æ–‡ä»¶
    if not Path(index_file).exists():
        print(f"Index file not found: {index_file}")
        print("Building index first...")
        builder = EfficientIndexBuilder()
        index = builder.build_index(reference_mgf)
        builder.save_index(index, index_file)
    
    # åˆ›å»ºå¤„ç†å™¨å¹¶å¼€å§‹å¤„ç†
    processor = SequentialProcessor(
        test_mgf=test_mgf,
        reference_mgf=reference_mgf,
        index_file=index_file,
        output_dir=output_dir
    )
    
    processor.process_all()

if __name__ == "__main__":
    main()
